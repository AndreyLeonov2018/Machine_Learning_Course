{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.21359436212\n"
     ]
    }
   ],
   "source": [
    "x = (9.5-9.57)/(0.4/math.sqrt(160))\n",
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0269"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "round(2* (1 - norm.cdf(-x)),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "from statsmodels.stats.weightstats import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreyleonov/anaconda2/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['norm']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'carat', u'depth', u'table', u'price', u'x', u'y', u'z'], dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('diamonds.txt', sep = '\\t', header = 0)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(labels = ['price'], axis =1)\n",
    "y = data['price'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_lin = LinearRegression()\n",
    "reg_lin.fit(X_train, y_train)\n",
    "lin_predict = reg_lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2140750.137628498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "mse_lin = mean_squared_error(y_test, lin_predict)\n",
    "print mse_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1974973.2160511552\n"
     ]
    }
   ],
   "source": [
    "reg_for = RandomForestRegressor(random_state=1)\n",
    "reg_for.fit(X_train, y_train)\n",
    "for_predict = reg_for.predict(X_test)\n",
    "mse_for = mean_squared_error(y_test, for_predict)\n",
    "print mse_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_lin > mse_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values.reshape(13485,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_dif = abs(lin_predict - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_diff = abs(for_predict.reshape(13485,1) - y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 294.55],\n",
       "       [1291.6 ],\n",
       "       [ 453.2 ],\n",
       "       ...,\n",
       "       [1426.  ],\n",
       "       [ 298.7 ],\n",
       "       [ 281.1 ]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=array([13.01772978]), pvalue=array([1.65517458e-38]))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_rel(reg_dif, for_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<statsmodels.stats.weightstats.CompareMeans at 0x127cbbc50>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: [59.831948, 115.079818]\n"
     ]
    }
   ],
   "source": [
    "print \"95%% confidence interval: [%f, %f]\" % cm2.tconfint_diff(usevar='unequal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mae_lin = mean_absolute_error(y_test, lin_predict)\n",
    "mse_for = mean_absolute_error(y_test, for_predict)\n",
    "v = np.array([mse_for, mae_lin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import _tconfint_generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_li = abs(y_test - lin_predict.reshape(13485,1))\n",
    "ae_for = abs(y_test - for_predict.reshape(13485,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 294.55],\n",
       "       [1291.6 ],\n",
       "       [ 453.2 ],\n",
       "       ...,\n",
       "       [1426.  ],\n",
       "       [ 298.7 ],\n",
       "       [ 281.1 ]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval: [74.287245, 100.624521]\n"
     ]
    }
   ],
   "source": [
    "print \"95%% confidence interval: [%f, %f]\" % DescrStatsW(ae_li - ae_for).tconfint_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 24*[0] + 10 * [1]\n",
    "y = 12*[0] + 4 * [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_stat_ind(sample1, sample2):\n",
    "    n1 = len(sample1)\n",
    "    n2 = len(sample2)\n",
    "    \n",
    "    p1 = float(sum(sample1)) / n1\n",
    "    p2 = float(sum(sample2)) / n2 \n",
    "    P = float(p1*n1 + p2*n2) / (n1 + n2)\n",
    "    \n",
    "    return (p1 - p2) / np.sqrt(P * (1 - P) * (1. / n1 + 1. / n2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_z_test(z_stat, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return 2 * (1 - scipy.stats.norm.cdf(np.abs(z_stat)))\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return scipy.stats.norm.cdf(z_stat)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return 1 - scipy.stats.norm.cdf(z_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3729"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(proportions_diff_z_test(proportions_diff_z_stat_ind(x, y), 'greater'), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('banknotes.txt', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(labels = ['real'], axis =1)\n",
    "y = data['real'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=50, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train.drop(labels = ['X4', 'X5', 'X6'], axis =1)\n",
    "X_test_1 = X_test.drop(labels = ['X4', 'X5', 'X6'], axis =1)\n",
    "X_train_2 = X_train.drop(labels = ['X1', 'X2', 'X3'], axis =1)\n",
    "X_test_2 = X_test.drop(labels = ['X1', 'X2', 'X3'], axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf1 = LogisticRegression().fit(X_train_1, y_train)\n",
    "clf1_predict = clf1.predict(X_test_1)\n",
    "clf2 = LogisticRegression().fit(X_train_2, y_train)\n",
    "clf2_predict = clf2.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.98\n"
     ]
    }
   ],
   "source": [
    "print clf1.score(X_test_1, y_test)\n",
    "print clf2.score(X_test_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for a difference between proportions: [-0.227020, 0.027020]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0032969384555543435"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print \"95%% confidence interval for a difference between proportions: [%f, %f]\" \\\n",
    "      % proportions_diff_confint_rel(clf1_predict, clf2_predict)\n",
    "proportions_diff_z_test(proportions_diff_z_stat_rel(err1,err2), 'two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportions_diff_confint_rel(sample1, sample2, alpha = 0.05):\n",
    "    z = scipy.stats.norm.ppf(1 - alpha / 2.)\n",
    "    sample = zip(sample1, sample2)\n",
    "    n = len(sample1)\n",
    "        \n",
    "    f = sum([1 if (x[0] == 1 and x[1] == 0) else 0 for x in sample])\n",
    "    g = sum([1 if (x[0] == 0 and x[1] == 1) else 0 for x in sample])\n",
    "    \n",
    "    left_boundary = float(f - g) / n  - z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    right_boundary = float(f - g) / n  + z * np.sqrt(float((f + g)) / n**2 - float((f - g)**2) / n**3)\n",
    "    return (left_boundary, right_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "err1 = y_test == clf1_predict\n",
    "err2 = y_test == clf2_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.3000547937203857, -0.059945206279614305)"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportions_diff_confint_rel( err1,err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  math import sqrt\n",
    "\n",
    "z = (541.5 - 525)/(100/sqrt(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.65"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0494714680336481"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "(1 - norm.cdf(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.descriptivestats import sign_test\n",
    "from statsmodels.stats.weightstats import zconfint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WilcoxonResult(statistic=17.0, pvalue=0.2845026979112075)"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmf = [49,58,75,110,112,132,151,276,281,362]\n",
    "m0 = 200\n",
    "stats.wilcoxon(np.array(lmf) - m0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=81.0, pvalue=0.02900499272087373)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [22,22,15,13,19,19,18,20,21,13,13,15]\n",
    "y = [17,18,18,15,12,4,14,15,10]\n",
    "stats.mannwhitneyu(np.array(x), np.array(y), alternative = 'greater')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Incident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apr12.81</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov12.81</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar22.82</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nov11.82</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apr04.83</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jun18.83</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Aug30.83</td>\n",
       "      <td>22.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Nov28.83</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Feb03.84</td>\n",
       "      <td>13.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Apr06.84</td>\n",
       "      <td>17.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aug30.84</td>\n",
       "      <td>21.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Oct05.84</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nov08.84</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jan24.85</td>\n",
       "      <td>11.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Apr12.85</td>\n",
       "      <td>19.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Apr29.85</td>\n",
       "      <td>23.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Jun17.85</td>\n",
       "      <td>21.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jul29.85</td>\n",
       "      <td>27.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Aug27.85</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Oct03.85</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Oct30.85</td>\n",
       "      <td>23.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Nov26.85</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Jan12.86</td>\n",
       "      <td>14.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Temperature  Incident\n",
       "0    Apr12.81         18.9         0\n",
       "1    Nov12.81         21.1         1\n",
       "2    Mar22.82         20.6         0\n",
       "3    Nov11.82         20.0         0\n",
       "4    Apr04.83         19.4         0\n",
       "5    Jun18.83         22.2         0\n",
       "6    Aug30.83         22.8         0\n",
       "7    Nov28.83         21.1         0\n",
       "8    Feb03.84         13.9         1\n",
       "9    Apr06.84         17.2         1\n",
       "10   Aug30.84         21.1         1\n",
       "11   Oct05.84         25.6         0\n",
       "12   Nov08.84         19.4         0\n",
       "13   Jan24.85         11.7         1\n",
       "14   Apr12.85         19.4         0\n",
       "15   Apr29.85         23.9         0\n",
       "16   Jun17.85         21.1         0\n",
       "17   Jul29.85         27.2         0\n",
       "18   Aug27.85         24.4         0\n",
       "19   Oct03.85         26.1         0\n",
       "20   Oct30.85         23.9         1\n",
       "21   Nov26.85         24.4         0\n",
       "22   Jan12.86         14.4         1"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('challenger.txt', sep='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "damaged = data[data.Incident == 1]['Temperature'].values\n",
    "undamaged = data[data.Incident == 0]['Temperature'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_samples(data, n_samples):\n",
    "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
    "    samples = data[indices]\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_intervals(stat, alpha):\n",
    "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
    "    return boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "damaged_mean_scores = map(np.mean, get_bootstrap_samples(damaged, 1000))\n",
    "undamaged_mean_scores = map(np.mean, get_bootstrap_samples(undamaged, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = map(lambda x: x[1] - x[0], zip(damaged_mean_scores, undamaged_mean_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% confidence interval for the difference between means [1.45040179 8.06457589]\n"
     ]
    }
   ],
   "source": [
    "print \"95% confidence interval for the difference between means\",  stat_intervals(mean_scores, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_t_stat_ind(sample1, sample2):\n",
    "    return np.mean(sample1) - np.mean(sample2)\n",
    "def get_random_combinations(n1, n2, max_combinations):\n",
    "    index = range(n1 + n2)\n",
    "    indices = set([tuple(index)])\n",
    "    for i in range(max_combinations - 1):\n",
    "        np.random.shuffle(index)\n",
    "        indices.add(tuple(index))\n",
    "    return [(index[:n1], index[n1:]) for index in indices]\n",
    "def permutation_zero_dist_ind(sample1, sample2, max_combinations = None):\n",
    "    joined_sample = np.hstack((sample1, sample2))\n",
    "    n1 = len(sample1)\n",
    "    n = len(joined_sample)\n",
    "    \n",
    "    if max_combinations:\n",
    "        indices = get_random_combinations(n1, len(sample2), max_combinations)\n",
    "    else:\n",
    "        indices = [(list(index), filter(lambda i: i not in index, range(n))) \\\n",
    "                    for index in itertools.combinations(range(n), n1)]\n",
    "    \n",
    "    distr = [joined_sample[list(i[0])].mean() - joined_sample[list(i[1])].mean() \\\n",
    "             for i in indices]\n",
    "    return distr\n",
    "def permutation_test(sample, mean, max_permutations = None, alternative = 'two-sided'):\n",
    "    if alternative not in ('two-sided', 'less', 'greater'):\n",
    "        raise ValueError(\"alternative not recognized\\n\"\n",
    "                         \"should be 'two-sided', 'less' or 'greater'\")\n",
    "    \n",
    "    t_stat = permutation_t_stat_ind(sample, mean)\n",
    "    \n",
    "    zero_distr = permutation_zero_dist_ind(sample, mean, max_permutations)\n",
    "    \n",
    "    if alternative == 'two-sided':\n",
    "        return sum([1. if abs(x) >= abs(t_stat) else 0. for x in zero_distr]) / len(zero_distr)\n",
    "    \n",
    "    if alternative == 'less':\n",
    "        return sum([1. if x <= t_stat else 0. for x in zero_distr]) / len(zero_distr)\n",
    "\n",
    "    if alternative == 'greater':\n",
    "        return sum([1. if x >= t_stat else 0. for x in zero_distr]) / len(zero_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.005700\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "print \"p-value: %f\" % permutation_test(damaged, undamaged, max_permutations = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
